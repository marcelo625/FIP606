[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula 10.html",
    "href": "Aula 10.html",
    "title": "Aula 10.1",
    "section": "",
    "text": "ANOVA 1 fator\nExperimento com um fator em DIC para comparar o crescimento micelial de diferentes espécies de um fungo fitopatogênico. A resposta a se estudada é a TCM = Taxa de crescimento micelial.\nman-wilker will cosicom\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(viridis)\nmicelial <- read_excel(\"dados-diversos.xlsx\", \"micelial\")\nhead(micelial)\n\n# A tibble: 6 × 3\n  especie   rep   tcm\n  <chr>   <dbl> <dbl>\n1 Fasi        1  1.5 \n2 Fasi        2  1.59\n3 Fasi        3  1.52\n4 Fasi        4  1.52\n5 Fasi        5  1.24\n6 Fasi        6  1.29\n\nmicelial |> \n  ggplot(aes(especie, tcm, fill = especie)) + \n  geom_boxplot() + \n  scale_fill_manual(values = viridis_pal(option = \"viridis\")(5), labels = expression(italic(\"F. asiaticum\"), italic(\"F. austroamericanum\"), italic(\"F. castaderiae\"), italic(\"F. graminearum\"), italic(\"F. meridionale\"))) +\n  labs (y = \"Mycelium Growth Rate\", x = \" \", fill = \"Species\") +\n    theme_classic()\n\n\n\nggsave(\"MGR.jpeg\", dpi = 300, width = 9, height = 6)\n\n\naov1 <- aov(tcm ~ especie, data = micelial)\nsummary(aov1)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nespecie      4 0.4692 0.11729   1.983  0.117\nResiduals   37 2.1885 0.05915               \n\nlibrary(performance)\ncheck_heteroscedasticity(aov1)\n\nOK: Error variance appears to be homoscedastic (p = 0.175).\n\ncheck_normality(aov1)\n\nOK: residuals appear as normally distributed (p = 0.074).\n\n\n\n\n\n\ninsects <- tbl_df(InsectSprays) |> \n  select(spray, count)\n\n\ninsects |> \n  ggplot(aes(x = spray, y = count)) +\n  geom_boxplot()\n\n\n\n\n\naov2 <- aov(count ~ spray, data = insects)\nsummary(aov2)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5   2669   533.8    34.7 <2e-16 ***\nResiduals   66   1015    15.4                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#vamos verificar as premicias agora\n\ncheck_heteroscedasticity(aov2)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\ncheck_normality(aov2)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\n#vou transformar os dados\naov3 <- aov(sqrt(count) ~spray, data = insects)\nsummary(aov3)\n\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5  88.44  17.688    44.8 <2e-16 ***\nResiduals   66  26.06   0.395                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_heteroscedasticity(aov3)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\ncheck_normality(aov3)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\n\nanam\n\nlibrary(emmeans)\naov3_means <- emmeans(aov2, ~spray,\n                      type = \"response\")\n\naov3_means\n\n spray emmean   SE df lower.CL upper.CL\n A      14.50 1.13 66   12.240    16.76\n B      15.33 1.13 66   13.073    17.59\n C       2.08 1.13 66   -0.177     4.34\n D       4.92 1.13 66    2.656     7.18\n E       3.50 1.13 66    1.240     5.76\n F      16.67 1.13 66   14.406    18.93\n\nConfidence level used: 0.95 \n\npwpm(aov3_means)\n\n        A       B       C       D       E       F\nA [14.50]  0.9952  <.0001  <.0001  <.0001  0.7542\nB  -0.833 [15.33]  <.0001  <.0001  <.0001  0.9603\nC  12.417  13.250 [ 2.08]  0.4921  0.9489  <.0001\nD   9.583  10.417  -2.833 [ 4.92]  0.9489  <.0001\nE  11.000  11.833  -1.417   1.417 [ 3.50]  <.0001\nF  -2.167  -1.333 -14.583 -11.750 -13.167 [16.67]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\n#o argumento type = \"response\" faz ele entender que há uma transformação do tipo r2\n#você pode ver outras formas de transformação\n#você pode usar não paramétrico - usando kruskal-wallis\n\nkruskal.test(count ~spray, data = insects)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nlibrary(agricolae)\nkruskal(insects$count, insects$spray,\n        console = TRUE)\n\n\nStudy: insects$count ~ insects$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\ninsects$spray,  means of the ranks\n\n  insects.count  r\nA      52.16667 12\nB      54.83333 12\nC      11.45833 12\nD      25.58333 12\nE      19.33333 12\nF      55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  insects$count groups\nF      55.62500      a\nB      54.83333      a\nA      52.16667      a\nD      25.58333      b\nE      19.33333     bc\nC      11.45833      c\n\naov3_means\n\n spray emmean   SE df lower.CL upper.CL\n A      14.50 1.13 66   12.240    16.76\n B      15.33 1.13 66   13.073    17.59\n C       2.08 1.13 66   -0.177     4.34\n D       4.92 1.13 66    2.656     7.18\n E       3.50 1.13 66    1.240     5.76\n F      16.67 1.13 66   14.406    18.93\n\nConfidence level used: 0.95 \n\n\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(aov3_means)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nqualidade ajuste do modelo\n\n# não paramétrico\nkruskal.test(count ~ spray, data = insects)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nlibrary(agricolae)\nkruskal(insects$count, insects$spray, \n        console = TRUE)\n\n\nStudy: insects$count ~ insects$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\ninsects$spray,  means of the ranks\n\n  insects.count  r\nA      52.16667 12\nB      54.83333 12\nC      11.45833 12\nD      25.58333 12\nE      19.33333 12\nF      55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  insects$count groups\nF      55.62500      a\nB      54.83333      a\nA      52.16667      a\nD      25.58333      b\nE      19.33333     bc\nC      11.45833      c\n\n\n\n\nModelos genereralizados\n\nlibrary(DHARMa)\n\nglm1 <- glm(count ~spray,\n            data = insects,\n            family = poisson(link = \"identity\"))\nplot(simulateResiduals(glm1))\n\n\n\n\n\nsummary(glm1)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson(link = \"identity\"), \n    data = insects)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3852  -0.8876  -0.1482   0.6063   2.6922  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  14.5000     1.0992  13.191  < 2e-16 ***\nsprayB        0.8333     1.5767   0.529    0.597    \nsprayC      -12.4167     1.1756 -10.562  < 2e-16 ***\nsprayD       -9.5833     1.2720  -7.534 4.92e-14 ***\nsprayE      -11.0000     1.2247  -8.981  < 2e-16 ***\nsprayF        2.1667     1.6116   1.344    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 3\n\nglm1_means <- emmeans(glm1, ~ spray)\ncld(glm1_means)\n\n spray emmean    SE  df asymp.LCL asymp.UCL .group\n C       2.08 0.417 Inf      1.27      2.90  1    \n E       3.50 0.540 Inf      2.44      4.56  12   \n D       4.92 0.640 Inf      3.66      6.17   2   \n A      14.50 1.099 Inf     12.35     16.65    3  \n B      15.33 1.130 Inf     13.12     17.55    3  \n F      16.67 1.179 Inf     14.36     18.98    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "aula 14.html",
    "href": "aula 14.html",
    "title": "aula 14",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\n\nConjunto de dados:\n\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\n\nestande |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  facet_wrap(~ exp)+\n  ylim(0,max(estande$nplants))+\n  geom_smooth(se =  F)\n\n\n\n\n\nestande2 <- estande |>\n  filter(exp ==2) |>\n  group_by(trat) |>\n  summarise(mean_nplants = mean(nplants))\n  \nestande2|>\n  ggplot(aes(trat, mean_nplants))+\n  geom_point()+\n  #geom_line()\n  geom_smooth(formula = y ~ poly(x, 2), method = \"lm\", color = \"black\")+\n  annotate(geom = \"text\", \n           x = 25, y = 70,\n           label = \"y = 66.3 - 1.777x + 0.0222x2\n           R2 = 0.0.88\")\n\n\n\n\nolhando o ajuste do modelo quadrático\n\nestande2 <- estande2 |>\n  mutate(trat2 = trat^2)\n  m1 <- lm(mean_nplants ~ trat, data = estande2)\nsummary(m1)\n\n\nCall:\nlm(formula = mean_nplants ~ trat, data = estande2)\n\nResiduals:\n     1      2      3      4      5      6 \n12.764 -2.134 -6.782 -3.327 -4.669  4.147 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     4.5505  13.402 0.000179 ***\ntrat         -0.7007     0.2012  -3.483 0.025294 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.117 on 4 degrees of freedom\nMultiple R-squared:  0.752, Adjusted R-squared:   0.69 \nF-statistic: 12.13 on 1 and 4 DF,  p-value: 0.02529\n\n\n\nhist(m1$residuals)\n\n\n\n\n\nm2 <- lm(mean_nplants ~ trat + trat2,\n         data = estande2)\nsummary(m2)\n\n\nCall:\nlm(formula = mean_nplants ~ trat + trat2, data = estande2)\n\nResiduals:\n      1       2       3       4       5       6 \n 7.4484 -4.4200 -6.4386  1.0739  3.0474 -0.7111 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 66.30156    4.70800  14.083 0.000776 ***\ntrat        -1.77720    0.62263  -2.854 0.064878 .  \ntrat2        0.02223    0.01242   1.790 0.171344    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.517 on 3 degrees of freedom\nMultiple R-squared:  0.8801,    Adjusted R-squared:  0.8001 \nF-statistic: 11.01 on 2 and 3 DF,  p-value: 0.04152\n\n\n\nAIC(m1, m2)\n\n   df      AIC\nm1  3 45.72200\nm2  4 43.36151\n\n\n#Duas variáveis resposta\n\nmofo <- read_excel(\"dados-diversos.xlsx\", \"mofo\")\nmofo |> \n  ggplot(aes(inc, yld)) +\n  geom_point() + \n  geom_smooth(se = F, method = \"lm\") + \n  facet_wrap(~study) \n\n\n\n\n\nmofo1 <- mofo |> \n  filter(study ==1)\nmofo1\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1     1    76  2194  2265\n 2     1     2    53  1663  2618\n 3     1     3    42  1313  2554\n 4     1     4    37  1177  2632\n 5     1     5    29   753  2820\n 6     1     6    42  1343  2799\n 7     1     7    55  1519  2503\n 8     1     8    40   516  2967\n 9     1     9    26   643  2965\n10     1    10    18   400  3088\n11     1    11    27   643  3044\n12     1    12    28   921  2925\n13     1    13    36  1196  2867\n\ncor.test(mofo$inc, mofo$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo$inc and mofo$yld\nt = -2.9274, df = 50, p-value = 0.005133\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.5934601 -0.1223842\nsample estimates:\n       cor \n-0.3825092 \n\n\n\nmofo2 <- mofo |> \n  filter(study == 2)\nmofo2\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     2     1    76  1331  2257\n 2     2     2    44   756  2393\n 3     2     3    24   338  2401\n 4     2     4    33   581  2568\n 5     2     5    37   588  2320\n 6     2     6    34   231  2308\n 7     2     7    31   925  2389\n 8     2     8    16   119  2614\n 9     2     9    10   394  2681\n10     2    10     8   206  2694\n11     2    11    15   275  2674\n12     2    12     7   131  2666\n13     2    13    19   588  2454\n\ncor.test(mofo2$inc, mofo2$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo2$inc and mofo2$yld\nt = -4.6638, df = 11, p-value = 0.0006894\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9426562 -0.4790750\nsample estimates:\n       cor \n-0.8149448 \n\n\n\nmofo4 <- mofo |> \n  filter(study == 4)\nmofo4\n\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     4     1    69  6216  1893\n 2     4     2    39  2888  2451\n 3     4     3    41  2272  2232\n 4     4     4    39  2868  2609\n 5     4     5    40  2412  2383\n 6     4     6    40  2372  2480\n 7     4     7    44  3424  2577\n 8     4     8    43  1744  2367\n 9     4     9    26  1456  2769\n10     4    10    29  1732  2907\n11     4    11    30  1080  2298\n12     4    12    34  1592  2976\n13     4    13    44  3268  2200\n\ncor.test(mofo4$inc, mofo4$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo4$inc and mofo4$yld\nt = -3.7242, df = 11, p-value = 0.003357\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9194503 -0.3327077\nsample estimates:\n       cor \n-0.7467931 \n\n\n\nmofo3 <- mofo |> \n  filter(study == 3)\n\n\ncor.test(mofo3$inc, mofo3$yld)\n\n\n    Pearson's product-moment correlation\n\ndata:  mofo3$inc and mofo3$yld\nt = -10.9, df = 11, p-value = 3.105e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9872663 -0.8579544\nsample estimates:\n      cor \n-0.956692 \n\ncor(mofo3 |> select(3:5))\n\n           inc        scl       yld\ninc  1.0000000  0.8441514 -0.956692\nscl  0.8441514  1.0000000 -0.836512\nyld -0.9566920 -0.8365120  1.000000\n\n\n\ncor(mofo1 |> select(3:5))\n\n           inc        scl        yld\ninc  1.0000000  0.9128688 -0.8999278\nscl  0.9128688  1.0000000 -0.9222418\nyld -0.8999278 -0.9222418  1.0000000\n\npcor <- cor(mofo1 |> select(3:5))\n\n\nlibrary(corrplot)\ncorrplot(pcor, \n         method = \"number\", \n         type = \"lower\")\n\n\n\n\nVocê pode usar o método de spearman quando não há normalidaden usando o argumento “method = ‘spearman’” na função “cor.test” ou então na função “cor”\nO padrão da função é pearson, então quando não há normalidade você pode usar o teste não-paramétrico\nse usa o método de “Kendall” quando a variável é ordinal e não assume normalidade\nLER EM CASA SOBRE ANÁLISE DE REGRESSÃO E ANÁLISE DE CORRELAÇÃO PESQUISAR TUTORIAIS NA WEB\nQuando eu vou usar um modelo linear, ou quando usar um modelo quadrático? quando usar cada tipo de modelo??\nou modelo logistico curva de saturaççao\nvamos usar a função == nls\npara curvva de dose respósta pesquisar como calculcar o EC50\na gente pode transformar essa regressão linear para log para linearizar\nQuando a gente pode usar isso? vamos usar o pacote dos modelos logísticos usando o pacote…. (ele esqueceu o nome)"
  },
  {
    "objectID": "Aula 15.html",
    "href": "Aula 15.html",
    "title": "Aula 15",
    "section": "",
    "text": "Quando as respóstas são categóricas\n\nlibrary(tidyverse)\nlibrary(readxl)\nsurvey <- read_excel(\"dados-diversos.xlsx\", \"survey\")\n\nsurvey |> \n  count(residue)\n\n# A tibble: 3 × 2\n  residue     n\n  <chr>   <int>\n1 corn      169\n2 soybean   281\n3 <NA>      216\n\nq <- table(survey$residue, survey$species)\nq\n\n         \n          Fgra Fspp\n  corn     147   22\n  soybean  255   26\n\n\n\nlibrary(janitor)\n\na <- survey |> \n  tabyl(year, species) |> \n  adorn_percentages()\n\n\nsurvey |> \n  filter(residue!= \"NA\") |> \n  count(residue, species) |> \n  ggplot(aes(residue, n, fill = species)) +\n           geom_col()\n\n\n\n\n\nchisq.test(q)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  q\nX-squared = 1.1997, df = 1, p-value = 0.2734\n\n\nO teste de fisher é quando temos numeros muito pequenos menor que 6 ou 5, porque o teste vai levar em coonsideração esses valores peqeunos de frequência\n\na <- table(survey$residue, survey$inc_class)\nchisq.test(a)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  a\nX-squared = 2.6165, df = 1, p-value = 0.1058\n\nfisher.test(a)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  a\np-value = 0.09855\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.4492084 1.0721250\nsample estimates:\nodds ratio \n  0.696718 \n\n\n\nsurvey |> \n  filter(residue != \"NA\") |> \n  count(residue, inc_class) |> \n  ggplot(aes(residue, n, fill = inc_class)) +\n  geom_col()\n\n\n\n\n\ncurve <- read_excel(\"dados-diversos.xlsx\", \"curve\")\ncurve\n\n# A tibble: 60 × 4\n   Irrigation   rep   day severity\n   <chr>      <dbl> <dbl>    <dbl>\n 1 Furrow         1     0    0.01 \n 2 Furrow         2     0    0.01 \n 3 Furrow         3     0    0.01 \n 4 Furrow         1     7    0.036\n 5 Furrow         2     7    0.036\n 6 Furrow         3     7    0.04 \n 7 Furrow         1    14    0.097\n 8 Furrow         2    14    0.097\n 9 Furrow         3    14    0.114\n10 Furrow         1    21    0.114\n# ℹ 50 more rows\n\ncurve2 <- curve |> \n  group_by(Irrigation, day) |> \n  summarize(mean_severity = mean(severity))\n\ncurve2 |> \n  ggplot(aes(day, mean_severity, color = Irrigation)) +\n  geom_point() +\n  geom_line()\n\n\n\n#geom_errorbar(aes(ymin = mean_severity - sd_severity, ymax = mean_severity + sd_severity)) +\n\n\nlibrary(epifitter)\ncurve3 <- curve |> \n  group_by(Irrigation, rep) |> \n  summarise(audpc = AUDPC(day, severity, y_proportion = F))\n\n#passar para o formato largo\n\ncurve4 <- curve3 |> \n  pivot_wider(1, names_from = Irrigation, \n            values_from = audpc)\n\nt.test(curve4$Drip, curve4$Furrow)\n\n\n    Welch Two Sample t-test\n\ndata:  curve4$Drip and curve4$Furrow\nt = -1.3773, df = 3.079, p-value = 0.26\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.3421436  0.5231436\nsample estimates:\nmean of x mean of y \n 13.38983  13.79933 \n\n\nFazer um exercício agora\n\ntw <- read_excel(\"tan-spot-wheat.xlsx\")\n\n\ntw2 <- tw |> \n  mutate(lesion_size = as.numeric(lesion_size))\n\ntw3 <- tw2 |> \n  group_by(silicio, hai, cult) |> \n  summarize(mean_lesion = mean(lesion_size),\n            sd_lesion = sd(lesion_size))\n\n\ntw3 |> \n  ggplot(aes(hai, mean_lesion, color = silicio)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = mean_lesion - sd_lesion, \n                    ymax = mean_lesion + sd_lesion), width = 0.2) +\n  geom_line() +\n  facet_wrap(~cult) +\n  labs(y = \"Lesion size(mm)\") +\n  labs(x = \"Hours after inoculation\", color = \"Treatment\") +\n  theme_light()\n\n\n\n\nA partir daqui, era para calcular a AUPCD, mas tudo desandou. E nada está certo!!!"
  },
  {
    "objectID": "Aula 16.html",
    "href": "Aula 16.html",
    "title": "Aula 16",
    "section": "",
    "text": "Vamos precisar instalar os pacotes rnaturalearthhires do github e rnaturalearth do CRAN\n\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\nlibrary(r4pde)\nlibrary(ggspatial)\n\n\nsbr<- RustSoybean\n\nBRA <- ne_countries(country = \"nigeria\",\n                    returnclass = \"sf\")\n\nggplot(BRA) + geom_sf(fill = \"white\")\n\n\n\n\n\nBRA <- ne_states(country = \"nigeria\",\n                    returnclass = \"sf\")\n\nggplot(BRA) + geom_sf(color = \"white\", \n                      fill = \"darkgreen\") +\n  theme_void()\n\n\n\n\n\nsbr2 <- sbr |> \n  separate(planting,  into = c(\"year\", \"month\", \"day\"), sep = \"-\", remove = FALSE)\n\n\nBRA <- ne_states(country = \"brazil\",\n                    returnclass = \"sf\")\nMG <- BRA |> filter(name_en == \"Minas Gerais\")\n\nggplot(BRA) + \n  geom_sf(fill = \"white\") + \n  #geom_sf(data = MG, color = \"black\", fill = \"blue\")\n  geom_point(data = sbr2, \n             aes(longitude, latitude, color = year), \n             alpha = 0.5) + \n  geom_hline(yintercept = -23, \n             linetype = \"dashed\",\n             color = \"gray\") +\n  theme_classic() +\n  annotation_north_arrow(style = north_arrow_nautical()) +\n  annotation_scale(location = \"br\") + theme(legend.position = \"top\")\n\n\n\n\n\nggplot(BRA) + \n  geom_sf(fill = \"white\") + \n  #geom_sf(data = MG, color = \"black\", fill = \"blue\")\n  geom_point(data = sbr2, \n             aes(longitude, latitude, color = year, size = severity), \n             alpha = 0.5) + \n  geom_hline(yintercept = -23, \n             linetype = \"dashed\",\n             color = \"gray\") +\n  theme_classic() +\n  annotation_north_arrow(style = north_arrow_nautical()) +\n  annotation_scale(location = \"br\")"
  },
  {
    "objectID": "aula 18.html",
    "href": "aula 18.html",
    "title": "Aula 18",
    "section": "",
    "text": "Analisando variáveis que não apresentam normalidade mas são dois fatores. Então a alternativa é transformar para rank e fazer a anova para verificar se tem interação.\n\nlibrary(readxl)\nlibrary(tidyverse)\nmicelial <- read_excel(\"~/Análise e Visualização de Dados/dados-diversos.xlsx\", \"fungicida_vaso\")\n\nmicelial <- micelial |> \n  mutate(inc = inf_seeds/n_seeds*100,\n         rank_inc = rank(inc))\n\nrank_anova <- aov(rank_inc ~ treat*dose, data = micelial)\nsummary(rank_anova)\n\n            Df Sum Sq Mean Sq F value  Pr(>F)   \ntreat        1 220.00  220.00  14.204 0.00168 **\ndose         1 105.34  105.34   6.801 0.01904 * \ntreat:dose   1  80.34   80.34   5.187 0.03684 * \nResiduals   16 247.82   15.49                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nmeans_rank <- emmeans::emmeans(rank_anova, ~treat | dose)\nmeans_rank\n\ndose = 0.5:\n treat        emmean   SE df lower.CL upper.CL\n Ionic liquid  18.00 1.76 16    14.27     21.7\n Tebuconazole   6.90 1.76 16     3.17     10.6\n\ndose = 2.0:\n treat        emmean   SE df lower.CL upper.CL\n Ionic liquid   9.75 1.61 16     6.34     13.2\n Tebuconazole   6.75 1.97 16     2.58     10.9\n\nConfidence level used: 0.95 \n\n\nNa tabela se coloca os dados originais com as letrinhas diferindo. Mas se especifica no artigo que a estatística foi realizada com os dados em rank.\n\nlibrary(MASS)\ninsects <-InsectSprays\n\nb <- boxcox(lm(insects$count+0.1 ~1))\n\n\n\nlambda <- b$x[which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n\n\ninsects$count2 <- (insects$count ^ lambda - 1)/lambda\n\nhist(insects$count2)"
  },
  {
    "objectID": "Aula 3.html",
    "href": "Aula 3.html",
    "title": "Aula 3",
    "section": "",
    "text": "O pacote datasets é o mais básico, porque ele já vem instalado no R. Alguns dados são os dados cars, Orange, Plant Growth e etc.\n\ncars2 <- cars #eu criei um dataframe chamado cars2 que é clone do dataframe cars\n\nEle tem cada variável em uma coluna, e as linhas tem uma variável idependente. Pesquisar formatos largo ou longo\n\nspeed <- cars2$speed #Aqui eu atribui a variável speed uma variável que estava dentro de um dataframen, o dataframe cars2\n\nPara carregar um dataframe de pacote, você primeiro precisa carregar um pacote e depois atribuir a um nome o dataset.\n\n#aqui eu carreguei um dataframe de um pacote\n\nlibrary(r4pde) #então eu carrego o pacote\ndf <- RustSoybean #aqui eu atribui a df o dataframe RustSoybean\n\n\nlibrary(readxl)\nmagnesio <- read_excel('dados-diversos.xlsx') #NÃO MODIFICANDO OS ARGUMENTOS ELE VAI ABRIR COMO PADRÃO A ABA 1\n\n\nescala <- read_excel('dados-diversos.xlsx', 2) #aqui eu modifiquei o argumento sheet e modifiquei para abrir a aba 2, ao invés da primeira aba que é aberta como padrão\n\nabrir o .csv\n\nlibrary('tidyverse')\nmagnesio2 <- read.csv('dados-diversos.csv')\nmagnesio3 <- read_csv('dados-diversos.csv')\nhelp(\"read_csv\")\n\nRead a delimited file (including CSV and TSV) into a tibble\nTibble é um formato de tabela dentro do dityverse. É um objeto diferente dentro do pacote readr que é um pacote dentro do ecossistema tidyverse.\n\nmagnesio4 <- read.table ('dados-diversos.txt', header = TRUE) \n\n#perguntar a monalisa o porque a planilha está abrindo como se estivesse em csv\n\nPlanilha google\n\nlibrary(gsheet)\nmagnesio5 <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844')\n\ncada aba da planilha online tem um identificador (url) diferente. Então o identificador já é específico para cada aba.\n\nsurvey <- gsheet2tbl('https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=366054269')\n\nSe você achar um arquivo csv na internet, você não precisa baixá-lo para usar. Você pode carregá-lo diretamente da internet.\n\nfusarium <- read_csv('https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/fusarium_banana.csv')"
  },
  {
    "objectID": "Aula 6.html",
    "href": "Aula 6.html",
    "title": "Aula 6",
    "section": "",
    "text": "Scatter plot\n\nlibrary(gsheet)\nlibrary(readxl)\nfungicida <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\nfungicida |>\n  ggplot(aes(trat, sev, color = trat)) +\n  geom_jitter(width = 0.1,\n              color = \"grey60\") +\n  stat_summary(fun.data = mean_se,\n               color = \"red\")\n\n\n\n\n\nfungicida |> \n  ggplot(aes(sev, yld)) +\n  geom_point(size = 3) +\n  scale_color_colorblind() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\nfungicida |> \n  ggplot(aes(sev, yld)) +\n  geom_point(size = 3) +\n  scale_color_colorblind() +\n  geom_smooth(method = \"lm\",\n              se = FALSE,\n              color = \"red\",\n              linetype = 3)\n\n\n\n\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"milho\")\nmilho |> \n    ggplot(aes(hybrid, yield, color = method)) +\n  geom_jitter()\n\n\n\n\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"milho\")\nmilho |> \n    ggplot(aes(hybrid, index, color = method, size = yield)) +\n  geom_jitter()\n\n\n\n\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"milho\")\nmilho |> \n    ggplot(aes(method, yield, color = method, size = index)) +\n  geom_jitter(width = 0.1) +\n  facet_wrap(~hybrid)\n\n\n\n\n\ncy <- milho |> \n  ggplot(aes(yield)) +\n  #facet_wrap(~hybrid) +\n  geom_histogram(bins = 10,\n                 color = \"black\",\n                 fill = \"green\") +\n  theme_clean() +\n  labs(y = \" \", x = \"Yield\") \n\n\ndi <- milho |> \n  ggplot(aes(index)) +\n  #facet_wrap(~hybrid) +\n  geom_histogram(bins = 10,\n                 color = \"black\",\n                 fill = \"green\") +\n  theme_clean() +\n  labs(y = \" \", x = \"Diseaase Index\") \n\n\nlibrary(patchwork)\n(cy | di) +\n  plot_annotation(tag_levels = \"A\") \n\n\n\nggsave(\"histograms.png\")\n\n\nmilho |> \n  ggplot(aes(x = index)) +\n  geom_density()\n\n\n\n\n\nmilho |> \n  ggplot(aes(index, yield)) +\n  geom_density_2d()\n\n\n\n\n\ninsect <- read_excel(\"dados-diversos.xlsx\", \"mortalidade\")\nlibrary(tidyverse)\n\ninsect |> \n  pivot_longer(2:3,\n               names_to = \"status\",\n               values_to = \"value\") |> \n  ggplot(aes(inseticida, value, fill = status)) + geom_col() + theme_clean()"
  },
  {
    "objectID": "Aula 7.html",
    "href": "Aula 7.html",
    "title": "Aula 7",
    "section": "",
    "text": "Carregando bibliotecas\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nmofo <- read_excel(\"~/Análise e Visualização de Dados/dados-diversos.xlsx\", \"mofo\")\n\nmofo |> \n  ggplot(aes(treat, yld)) +\n  geom_col() +\n  geom_point(color = \"red\") +\n  facet_wrap(~study)\n\n\n\n\n###Histograma\n\nh <- mofo |> \n  ggplot(aes(scl)) +\n  geom_histogram(bins = 10)\n\nb <- mofo |> \n  ggplot(aes(scl)) +\n  geom_boxplot()\n\nlibrary(patchwork)\n\nWarning: package 'patchwork' was built under R version 4.2.3\n\nh / b\n\n\n\n\nComo calcular a média rápida da variável scl dentro do conjunto mofo\n\nmean(mofo$scl)\n\n[1] 1639.096\n\n\nou então\n\nsummary(mofo)\n\n     study          treat         inc             scl            yld      \n Min.   :1.00   Min.   : 1   Min.   : 7.00   Min.   : 119   Min.   :1893  \n 1st Qu.:1.75   1st Qu.: 4   1st Qu.:26.00   1st Qu.: 588   1st Qu.:2438  \n Median :2.50   Median : 7   Median :34.00   Median :1337   Median :2678  \n Mean   :2.50   Mean   : 7   Mean   :35.10   Mean   :1639   Mean   :2780  \n 3rd Qu.:3.25   3rd Qu.:10   3rd Qu.:41.25   3rd Qu.:2382   3rd Qu.:3055  \n Max.   :4.00   Max.   :13   Max.   :76.00   Max.   :6216   Max.   :3702  \n\n\nPara transformação você pode usar o log ou sqrt criando uma variável nova no conjunto de dados apresentando os valores da transformação de determinada variável.\n\nmofo2 <- mofo |> \n  mutate(scl2 = sqrt(scl))\n\nhl <- mofo2 |> \n  ggplot(aes(scl2)) +\n  geom_histogram(bins = 10)\n\nh / hl \n\n\n\n\n\nsurvey <- read_excel(\"dados-diversos.xlsx\", \"survey\")\n\nsurvey |> \n  filter(state == \"RS\") |> \n  count(species, residue) |> \n  arrange (species) |> \n  rename(res = residue) |> \n  mutate(n_class = case_when(\n    n <30 ~ \"baixa\",\n    TRUE ~ \"Alta\"))\n\n# A tibble: 4 × 4\n  species res         n n_class\n  <chr>   <chr>   <int> <chr>  \n1 Fgra    corn      147 Alta   \n2 Fgra    soybean   255 Alta   \n3 Fspp    corn       22 baixa  \n4 Fspp    soybean    26 baixa"
  },
  {
    "objectID": "Aula 8.html",
    "href": "Aula 8.html",
    "title": "Aula 8",
    "section": "",
    "text": "#Calculando o Test T e o apresentando no R\nA função annotate sere para anotar qualquer informação no gráfico dentro da camada do ggplot:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\n\nmg <- read_excel(\"dados-diversos.xlsx\")\n\nmg |> \n  ggplot(aes(trat, comp)) +\n  \n  geom_jitter(width = 0.05)+\n  geom_boxplot(fill=NA, outlier.colour = NA) +\n  ylim(5, 20) +\n  annotate(geom = \"text\",\n           x = 0.6, y = 20,\n           label = \"t = 8.12; P < 0.001\")\n\n\n\n#a função trabalha com coordenadas, então para escolher a posição, é tentativa e erro. Sendo a variável Mg2 equivalente a 1 e a variável Control equivalente a 2.\n\npara usar o t.test, é preciso colocar os dados em colunas diferentes\nna função pivot wider (pega a coluna 1, e usa trat como nome e os valores de comp como calores)\n\nmg2 <- mg |> \n  pivot_wider(1,\n              names_from = trat,\n              values_from = comp)\n\nWarning: Specifying the `id_cols` argument by position was deprecated in tidyr 1.3.0.\nℹ Please explicitly name `id_cols`, like `id_cols = 1`.\n\nmg2\n\n# A tibble: 10 × 3\n     rep   Mg2 control\n   <dbl> <dbl>   <dbl>\n 1     1   9      13.7\n 2     2  12.5    15.9\n 3     3  10      15.7\n 4     4   8      14.2\n 5     5  13.2    15.9\n 6     6  11      16.5\n 7     7  10.8    18  \n 8     8   9.5    14.4\n 9     9  10.8    16.4\n10    10  10.4    16  \n\n\n\nt <- t.test(mg2$Mg2, mg2$control)\n\nlibrary(report)\n\nWarning: package 'report' was built under R version 4.2.3\n\nreport(t)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p < .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])"
  },
  {
    "objectID": "Aula 9.html",
    "href": "Aula 9.html",
    "title": "Aula 9",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\ndata_mg <- read_xlsx(\"dados-diversos.xlsx\")\n\ndat2 <- data_mg |> \n  group_by(trat) |> \n  summarise(\n    mean_comp = mean(comp),\n    sd_comp = sd(comp),\n    var_comp = var(comp),\n    n = n(),\n    se_comp = sd_comp / sqrt(n - 1),\n    ci = se_comp * qt(0.025, df = 9))\n\ndat2\n\n# A tibble: 2 × 7\n  trat    mean_comp sd_comp var_comp     n se_comp     ci\n  <chr>       <dbl>   <dbl>    <dbl> <int>   <dbl>  <dbl>\n1 Mg2          10.5    1.54     2.39    10   0.515 -1.16 \n2 control      15.7    1.27     1.61    10   0.424 -0.958\n\n\n\ndat2 |> \n  ggplot(aes(trat, mean_comp)) +\n  geom_col(width = 0.5, \n             fill = \"blue\") +\n  geom_point()  +\n  geom_errorbar(aes(ymin = mean_comp - ci,\n                    ymax = mean_comp + ci),\n                width = 0.05)+\n  ylim(0, 20) + labs(x = \" \", y = \" Mean size (mm) \")\n\n\n\n\n\nmg2 <- data_mg |> \n  pivot_wider(1, \n    names_from = trat,\n    values_from = comp) \n\n\n\nt <- t.test(mg2$Mg2, mg2$control, paired = F)\n\n#esse argumento paired é sobre a dependência dos dados. O padrão da função já é False, para teste de um conjunto de dados independentes. Mas em outros casos serão com um conjunto de dados dependentes, ou seja, será paired = True\n\n#EXEMPLO: quando a gente que ver a diferença do Mg2 no tempo\n\nlibrary(report)\nreport(t)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p < .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n\n\nO teste t é um teste paramêtrico. precisa assumir duas premicias: 1. Normalidade dos dados = Distribuição normal ou Gaussiana 2. Homocedasticidade = variância homogênia (a dispersão dos dados são parecidas)\nVisualmente a gente tem uma ideia, mas existem testes para auxiliar nas decisões: se vai precisar fazer transformação dos dados ou fazer modificações\n\npara testar a Homocedasticidade\nNo caso de dois grupos, a função que é usada é o “var.test” a hipotese nula é que as variancias são iguais\n\nattach(mg2) #a função desagrega as variáveis\n\nvar.test(Mg2, control)\n\n\n    F test to compare two variances\n\ndata:  Mg2 and control\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111 \n\n\nA normalidade pode ser testatada por Shapiro-wilk ou por uma análise visual. No caso do teste de shapiro, a hipotese nula é a de normalidade\n\nshapiro.test(Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  Mg2\nW = 0.97269, p-value = 0.9146\n\nshapiro.test(control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  control\nW = 0.93886, p-value = 0.5404\n\n\nA análise visual -> se os dados estiverem em cima da linha, então a gente assume a normalidade dos dados.\n\nqqnorm(Mg2)\nqqline(Mg2)\n\n\n\nqqnorm(control)\nqqline(control)\n\n\n\n\n\nescala <- read_excel(\"dados-diversos.xlsx\", \"escala\")\nhead(escala)\n\n# A tibble: 6 × 7\n  assessment rater acuracia precisao vies_geral vies_sistematico vies_constante\n  <chr>      <chr>    <dbl>    <dbl>      <dbl>            <dbl>          <dbl>\n1 Unaided    A        0.809    0.826      0.979            1.19         0.112  \n2 Unaided    B        0.722    0.728      0.991            0.922       -0.106  \n3 Unaided    C        0.560    0.715      0.783            1.16         0.730  \n4 Unaided    D        0.818    0.819      0.999            0.948       -0.00569\n5 Unaided    E        0.748    0.753      0.993            1.10         0.0719 \n6 Unaided    F        0.695    0.751      0.925            0.802        0.336  \n\nescala2 <- escala |> \n  select(assessment, rater, acuracia)\n\nescala2\n\n# A tibble: 20 × 3\n   assessment rater acuracia\n   <chr>      <chr>    <dbl>\n 1 Unaided    A        0.809\n 2 Unaided    B        0.722\n 3 Unaided    C        0.560\n 4 Unaided    D        0.818\n 5 Unaided    E        0.748\n 6 Unaided    F        0.695\n 7 Unaided    G        0.807\n 8 Unaided    H        0.781\n 9 Unaided    I        0.776\n10 Unaided    J        0.618\n11 Aided1     A        0.907\n12 Aided1     B        0.913\n13 Aided1     C        0.915\n14 Aided1     D        0.960\n15 Aided1     E        0.959\n16 Aided1     F        0.903\n17 Aided1     G        0.851\n18 Aided1     H        0.880\n19 Aided1     I        0.950\n20 Aided1     J        0.944\n\n\n\na <- escala2 |> \n  pivot_wider(1,\n    names_from = assessment,\n    values_from = acuracia)\n\n\n#Não tô conseguindo usar o attach\nt.test(a$Aided1, a$Unaided)\n\n\n    Welch Two Sample t-test\n\ndata:  a$Aided1 and a$Unaided\nt = 6.2288, df = 11.981, p-value = 4.423e-05\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.1202420 0.2496529\nsample estimates:\nmean of x mean of y \n0.9181913 0.7332439 \n\n\n\nvar.test(a$Aided1, a$Unaided)\n\n\n    F test to compare two variances\n\ndata:  a$Aided1 and a$Unaided\nF = 0.17041, num df = 9, denom df = 9, p-value = 0.01461\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.04232677 0.68605885\nsample estimates:\nratio of variances \n         0.1704073 \n\n\n\nshapiro.test(a$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  a$Aided1\nW = 0.92775, p-value = 0.4261\n\nshapiro.test(a$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  a$Unaided\nW = 0.87462, p-value = 0.1131\n\nt.test(a$Aided1, a$Unaided, paired = T, var.equal = F)\n\n\n    Paired t-test\n\ndata:  a$Aided1 and a$Unaided\nt = 5.9364, df = 9, p-value = 0.000219\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1144707 0.2554241\nsample estimates:\nmean difference \n      0.1849474 \n\n\nCaso não tivesse ocorrido normalidade, você pode transformar os dados até comprir com as premícias da análise paramétrica, ou então, trabalhar com os dados originais, mas usando estatística não-paramétrica.\nwilcox.test() é o teste não-paramétrico equivalende ao test t paramétrico não pareado.\n\nescala |>\n  ggplot(aes(assessment, acuracia)) + geom_boxplot() + geom_jitter()"
  },
  {
    "objectID": "aula11.html",
    "href": "aula11.html",
    "title": "Aula 11",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\n\ndat <- read_excel(\"dados-diversos.xlsx\", \"fungicida_vaso\")\n\ndat2 <- dat |> \n  mutate(inc = dis_sp/n_sp*100)\n\ndat2 |> \n  ggplot(aes(x = treat,\n             y = inc)) + \n  geom_jitter(width = 0.1) +\n  facet_wrap(~dose)\n\n\n\n\n\nm1 <- aov(inc ~ treat*dose,\n          data = dat2)\n\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ntreat        1  919.5   919.5   24.31 0.000151 ***\ndose         1  920.9   920.9   24.34 0.000150 ***\ntreat:dose   1  747.7   747.7   19.76 0.000407 ***\nResiduals   16  605.3    37.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAqui mostrou que tem interação entre o fungicida e a dose então se rejeita a hipótese nula\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.018).\n\n\nDeu falta de normalidade vamos ver a outra premiciia que é a homocedasticidade\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\n\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\n\nm2 <- aov(log(inc + 0.5) ~ treat*dose,\n          data = dat2)\nplot(simulateResiduals(m2))\n\n\n\n\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.180).\n\n\n\ncheck_normality(m2)\n\nWarning: Non-normality of residuals detected (p = 0.050).\n\n\n\nlibrary(emmeans)\nmeans_m2 <- emmeans(m2, ~treat*dose,\n                    type = \"response\")\nmeans_m2\n\n treat        dose response     SE df lower.CL upper.CL\n Ionic liquid  0.5    27.05 11.847 16   10.570    68.05\n Tebuconazole  0.5     1.21  0.737 16    0.188     3.76\n Ionic liquid  2.0     3.10  1.412 16    1.065     7.77\n Tebuconazole  2.0     1.42  0.925 16    0.194     4.83\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \n\n\n\nmeans_m3 <- emmeans(m2, ~treat | dose,\n                    type = \"response\")\n\n\nlibrary(multcompView)\nlibrary(multcomp)\ncld(means_m3)\n\ndose = 0.5:\n treat        response     SE df lower.CL upper.CL .group\n Tebuconazole     1.21  0.737 16    0.188     3.76  1    \n Ionic liquid    27.05 11.847 16   10.570    68.05   2   \n\ndose = 2.0:\n treat        response     SE df lower.CL upper.CL .group\n Tebuconazole     1.42  0.925 16    0.194     4.83  1    \n Ionic liquid     3.10  1.412 16    1.065     7.77  1    \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nmeans_m4 <- emmeans(m2, ~dose | treat,\n                    type = \"response\")\n\n\nlibrary(multcompView)\nlibrary(multcomp)\ncld(means_m4)\n\ntreat = Ionic liquid:\n dose response     SE df lower.CL upper.CL .group\n  2.0     3.10  1.412 16    1.065     7.77  1    \n  0.5    27.05 11.847 16   10.570    68.05   2   \n\ntreat = Tebuconazole:\n dose response     SE df lower.CL upper.CL .group\n  0.5     1.21  0.737 16    0.188     3.76  1    \n  2.0     1.42  0.925 16    0.194     4.83  1    \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log(mu + 0.5) scale \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAqui vai calccular o coeficiente de variação\n\nlibrary(agricolae)\ncv.model(m2)\n\n[1] 65.04818\n\n\nVer o trabalho “Imidazolium salts with antifungal potential for the controlof head blight of wheat caused by Fusarium graminearum”\nVamos trabalhar agora com dados de armazenamento de milho\n\nmilho <- read_excel(\"dados-diversos.xlsx\", \"armazena\")\n\nmilho |> \n  filter(tempo == 8) |> \n  ggplot(aes(factor(tipo), peso_mil, color = factor(umidade))) +\n  geom_jitter() + facet_wrap(~umidade)\n\n\n\n\nVer o trabalho “Qualidade físico-quimica de grãos de milho armazenados com diferentes umidades em ambientes hermético e não hermético”\n\nmilho2 <- milho |> \n  filter(tempo == 8)\n\nm2 <- aov(peso_mil ~factor(tipo)*factor(umidade), data = milho2)\n\nsummary(m2)\n\n                             Df Sum Sq Mean Sq F value   Pr(>F)    \nfactor(tipo)                  1  11215   11215  2375.8 3.64e-15 ***\nfactor(umidade)               2  42814   21407  4534.8  < 2e-16 ***\nfactor(tipo):factor(umidade)  2   2329    1165   246.7 1.79e-10 ***\nResiduals                    12     57       5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ntestanto tipo de inoculação na incidencia de fusarium em milho\n\nmilho3 <- read_excel(\"dados-diversos.xlsx\", \"milho\")\n\nm4 <- aov(yield ~hybrid*method,\n          data = milho3)\n\nsummary(m4)\n\n              Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid         5 105876446 21175289   8.312 2.66e-05 ***\nmethod         1     42951    42951   0.017    0.897    \nhybrid:method  5  10619453  2123891   0.834    0.534    \nResiduals     36  91709593  2547489                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nm5 <- aov(yield ~hybrid, data = milho3)\nsummary(m5)\n\n            Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid       5 105876446 21175289   8.688 1.02e-05 ***\nResiduals   42 102371996  2437428                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ncheck_heteroscedasticity(m4)\n\nOK: Error variance appears to be homoscedastic (p = 0.928).\n\n\n\nplot(simulateResiduals(m5))\n\n\n\n\n\nmedias_m5 <- emmeans(m5, ~hybrid)\nmedias_m5\n\n hybrid   emmean  SE df lower.CL upper.CL\n 30F53 HX  10598 552 42     9484    11712\n 30F53 YH   9309 552 42     8195    10423\n 30K64     11018 552 42     9904    12132\n 30S31H     8652 552 42     7538     9765\n 30S31YH    8056 552 42     6942     9170\n BG7049H   12402 552 42    11288    13516\n\nConfidence level used: 0.95 \n\ncld(medias_m5)\n\n hybrid   emmean  SE df lower.CL upper.CL .group\n 30S31YH    8056 552 42     6942     9170  1    \n 30S31H     8652 552 42     7538     9765  12   \n 30F53 YH   9309 552 42     8195    10423  123  \n 30F53 HX  10598 552 42     9484    11712   234 \n 30K64     11018 552 42     9904    12132    34 \n BG7049H   12402 552 42    11288    13516     4 \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\npwpm(medias_m5)\n\n         30F53 HX 30F53 YH   30K64  30S31H 30S31YH BG7049H\n30F53 HX  [10598]   0.5709  0.9942  0.1494  0.0254  0.2125\n30F53 YH     1288  [ 9309]  0.2643  0.9576  0.5999  0.0036\n30K64        -420    -1709 [11018]  0.0447  0.0059  0.4938\n30S31H       1946      658    2366 [ 8652]  0.9723  0.0003\n30S31YH      2541     1253    2962     595 [ 8056]  <.0001\nBG7049H     -1804    -3092   -1384   -3750   -4345 [12402]\n\nRow and column labels: hybrid\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\nPairwise P-value plot\n\npwpp(medias_m5)\n\n\n\n\nQuando não tem interação entre os fatores, recorre as análises dos fatores individuais."
  },
  {
    "objectID": "Aula13 (1).html",
    "href": "Aula13 (1).html",
    "title": "Aula13",
    "section": "",
    "text": "Quando se tem dados quantitativos, a análise de regressão é geralmente mais apropriada do que a análise de variância (ANOVA), pois a análise de regressão permite estudar a relação entre uma variável dependente (Y) e uma ou mais variáveis independentes (X).\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\n\n\n\nNa regressão linear simples, testamos a hipótese de que a reta de regressão (linha de melhor ajuste), que representa a relação entre as variáveis independentes e a variável dependente, tem um coeficiente de inclinação diferente de zero. Ou seja, testamos a hipótese de que a inclinação da reta de regressão é significativamente diferente de zero (testa se o p valor é diferente de 0).\nConjunto de dados estande (dados-diversos): Visualização em ggplot Para ajustar para uma regressão linear usa-se o argumento method = “lm” dentro da função geom_smooth.\n\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\nestande |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  facet_wrap(~ exp)+\n  geom_smooth(se =  F, method = \"lm\")\n\n\n\n\nPosteriomente, deve-se testar o modelo que melhor se ajusta aos dados.Pode-se testar fazer a análise de regressão para cada experimento (isola cada experimento) ou analisar em grupos (modelos mistos).\n\n\nPara isso, cria um novo objeto para os dados (exp1) e atribui estande a ele, depois deve-se filtrar o experimento que deseja e criar um objeto para esse conjunto para viabilizar a realização da análise de regressão.\nExp 1:\n\nexp1 <- estande |>\n  filter(exp == 1)\n\nm1 <- lm(nplants ~trat, data = exp1)\nsummary(m1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\nO valor do intercept e o valor de trat (slope) são utilizados na tabela. Intercept é o valor da variável dependente quando a variável independente é igual a zero. Já o slope é a medida da inclinação da linha de regressão, que representa a mudança na variável dependente associada a uma mudança na variável independente.\nPara o experimento 2:\n\nexp2 <- estande |>\n  filter(exp == 2)\n\nm2 <- lm(nplants ~trat, data = exp2)\nsummary(m2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\nPara o exp3:\n\nexp3 <- estande |>\n  filter(exp == 3)\n\nm3 <- lm(nplants ~trat, data = exp3)\nsummary(m3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\nlibrary(report)\nreport(m3)\n\nWe fitted a linear model (estimated using OLS) to predict nplants with trat\n(formula: nplants ~ trat). The model explains a statistically significant and\nsubstantial proportion of variance (R2 = 0.61, F(1, 22) = 34.19, p < .001, adj.\nR2 = 0.59). The model's intercept, corresponding to trat = 0, is at 95.75 (95%\nCI [89.63, 101.87], t(22) = 32.43, p < .001). Within this model:\n\n  - The effect of trat is statistically significant and negative (beta = -0.76,\n95% CI [-1.03, -0.49], t(22) = -5.85, p < .001; Std. beta = -0.78, 95% CI\n[-1.06, -0.50])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nGráfico para representar a regressão - Para unir os 3 graficos, usa o patchwork.\n\ng1 <- exp1 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24,\n           y = 70, label = \"y = 52.5 - 0.24x\")\n\ng2 <- exp2 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24,\n           y = 70, label = \"y = 60 - 0.07x\")\ng3 <- exp3 |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)+\n  annotate(geom = \"text\", x = 24,\n           y = 70, label = \"y = 95 - 0.07x\")\n\nlibrary(patchwork)\ng1|g2|g3\n\n\n\n\n\n\n\n\nEm um modelo misto, as observações são divididas em grupos ou subgrupos. Cada grupo pode ter um conjunto diferente de efeitos aleatórios e/ou fixos, dependendo da estrutura dos dados. Por exemplo, se os dados foram coletados em diferentes locais geográficos, podemos ter um efeito aleatório para cada local (como no caso do conjunto de dados estande).\n\nlibrary(lme4)\nmix <- lmer(nplants ~trat + (trat | exp),\n            data = estande)\nsummary(mix)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\n\nNo contexto do modelo, as variáveis são definidas da seguinte forma:\nnplants: a variável de resposta, representando o número de plantas. trat: a variável preditora, representando o tratamento. exp: a variável agrupadora, representando os diferentes experimentos. A especificação (trat | exp) na fórmula do modelo indica que o efeito do tratamento (trat) varia aleatoriamente entre os diferentes experimentos (exp).\nO resumo do modelo fornecerá uma série de informações estatísticas relevantes, incluindo os coeficientes estimados para os efeitos fixos e aleatórios, bem como os seus erros-padrão e valores de t. Além disso, serão exibidas estatísticas de ajuste do modelo, como o desvio residual, a variação total e a variação explicada pelo modelo.\n\nlibrary(car)\nAnova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: nplants\n      Chisq Df Pr(>Chisq)    \ntrat 11.985  1  0.0005362 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nQuando se usa o modelo misto, considera que todos os experimentos são agrupados, então considera que amostra é aleatória.\nPara fazer o modelo de regressão em grupo (misto) acrescenta-se na função aestetic o argumento group = exp.\n\nestande <- read_excel(\"dados-diversos.xlsx\", \"estande\")\nestande |>\n  ggplot(aes(trat, nplants, group = exp))+\n  geom_point()+\n  #facet_wrap(~ exp)+\n  geom_smooth(se =  F, method = \"lm\")\n\n\n\n\nEm geral, os modelos mistos são mais poderosos do que os modelos que tratam cada experimento isoladamente, pois levam em conta a variação tanto entre quanto dentro dos experimentos. Além disso, os modelos mistos permitem que os dados sejam analisados em sua totalidade, sem perder informações importantes sobre a estrutura dos dados."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bem-vindo!",
    "section": "",
    "text": "Isso é um arquivo Quarto Markdown .\nAqui serão organizadas e apresentadas todas as aulas da disciplina FIP606 - Análise e visualização de dados.\n\nSobre mim:\nMeu nome é Marcelo Gonçalves. Eu sou engenheiro agrônomo pela Universidade Federal Rural de Pernambuco e atualmente curso mestrado em fitopatologia na Universidade Federal de Viçosa. Durante a minha carreira acadêmica, me desenvolvi na área de fitossanidade. Adquirindo experiência em pesquisa com bactérias fitopatogênicas e fitovirologia. Atualmente, integro o Laboratório de Ecologia e Evolução de Vírus, localizado no Núcleo de Biotecnologia Aplicada à Agropecuária (BIOAGRO) .\nDurante a minha graduação, em agronomia, atuei em pesquisas com hortifruti, estudando patógenos de importância para o meloeiro e maracujazeiro usando ferramentas sorológicas, moleculares e de bioinformática. No mestrado, tenho dado foco em estudar a estrutura genética de populações e o efeito de forças que guiam a evolução de vírus de planta.\n\n\nMarcelo Gonçalves\nContato por e-mail: marcelo.h.goncalves@ufv.br"
  },
  {
    "objectID": "topico2.html",
    "href": "topico2.html",
    "title": "Fazendo Gráficos no R",
    "section": "",
    "text": "Gráficos com o Ggplot2\nPrimeiro, vamos carregar a biblioteca “tidyverse” e “readxl” para ler um arquivo chamado “dados-diversos.xlsx” salvo no diretório de trabalho usando a função “read_excel”, no entanto para abrir a tabela nomeada como “curve” e atribuí-la ao objeto ir.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nir <- read_excel(\"dados-diversos.xlsx\", \"curve\")\n\nNós vamos trabalhar também usando a biblioteca “Ggplot2”. No entanto, não é preciso carregá-la individualmente, porque ela já foi carregado junto ao tidyerse. Aqui vamos usar o símbolo |> que é chamado de pipe, o professor prefere usar o pipe porque as vezes é preciso fazer alterações dentro dos argumentos. No ggplot vamos adicionando camadas com o símbolo de +.\nEntão vamos criar um gráfico de dispersão com pontos representando dados sobre irrigação.\n\nir |> \n  ggplot(aes(Irrigation, severity, colour = Irrigation, shape = Irrigation)) + geom_point(alpha = 0.5)\n\n\n\n\nggplot(): Inicia um novo objeto de gráfico utilizando a função ggplot().\naes(Irrigation, severity, colour = Irrigation, shape = Irrigation): Define os mapeamentos estéticos dentro da função aes(). Aqui, Irrigation é mapeado para o eixo x, severity é mapeado para o eixo y, Irrigation é mapeado para a cor dos pontos e também para a forma dos pontos.\ngeom_point(alpha = 0.5): Adiciona uma camada geométrica de pontos ao gráfico usando a função geom_point(). O parâmetro alpha = 0.5 define a transparência dos pontos para 0.5, tornando-os parcialmente transparentes.\n\nir |> \n  ggplot(aes(day, severity, shape = Irrigation)) + geom_point(alpha = 0.5) + geom_line(colour = \"red\") + facet_wrap(~rep)\n\n\n\n\ngeom_line(colour = “red”): Adiciona uma camada geométrica de linhas ao gráfico usando a função geom_line(). As linhas são desenhadas na cor vermelha, conforme especificado pelo parâmetro colour.\nfacet_wrap(~rep): Divide o gráfico em painéis (subplots) com base nos valores da variável rep. Cada painel mostrará um subconjunto dos dados correspondente a um valor distinto de rep.\nNo entanto, nós também poderiamos usar a função filter para selecionar apenas um das repetições para fazer o gráfico de linhas,\n\nir |> \n  filter (rep == 1) |> \n  ggplot(aes(day, severity, shape = Irrigation)) + geom_point(alpha = 0.5) + geom_line(colour = \"red\")\n\n\n\n\nNo entanto, nós vamos usar a média das repetições para construir o nosso gráfico de linha\n\nir2 <- ir\nir2 |> \n  select(day, rep, severity) |> \n  group_by(day) |> \n  summarize(sev = mean(severity)) |> \n  ggplot(aes(day, sev*100))+\n  geom_point(colour = \"red\", size = 3)+\n  geom_line() + labs(x = \"Time(days)\", y = \"Severity (%)\", title = \"My first GGPLOT\", subtitle = \"M. H. O. Gonçalves\", caption = \"source: FIP 606\") + theme_classic() + scale_y_continuous(n.breaks = 10, limits = c(0,100)) + scale_x_continuous (breaks = c(0, 7, 14, 21, 28, 35, 42, 49, 56, 63))\n\n\n\n\nAqui\nir2 |> select(day, rep, severity) |> group_by(day) |> summarize(sev = mean(severity)): Utiliza o operador de encadeamento |> para criar um pipeline de operações no objeto ir2. A primeira operação é select(), que seleciona as colunas day, rep e severity do objeto ir2. Em seguida, a função group_by() agrupa os dados pelo valor da coluna day. Por fim, a função summarize() calcula a média da coluna severity para cada grupo definido por day, resultando em uma nova coluna chamada sev com as médias.\nlabs(x = “Time(days)”, y = “Severity (%)”, title = “My first GGPLOT”, subtitle = “M. H. O. Gonçalves”, caption = “source: FIP 606”): Define as etiquetas (labels) para os eixos x e y, o título do gráfico, o subtítulo e a legenda (caption) do gráfico.\ntheme_classic(): Aplica um tema clássico ao gráfico para ajustar a aparência.\nscale_y_continuous(n.breaks = 10, limits = c(0,100)): Ajusta a escala do eixo y para exibir 10 intervalos (n.breaks)e limita os valores entre 0 e 100 (limits).\nscale_x_continuous(breaks = c(0, 7, 14, 21, 28, 35, 42, 49, 56, 63)): Ajusta a escala do eixo x para exibir intervalos nos valores específicos indicados.\n\n\nBoxplot\nAgora vamos usar um conjunto de dados diferentes\n\nmg <- read_excel(\"dados-diversos.xlsx\")\n\ngeom_boxplot cria um boxplot\n\np_box <- mg |>\n  ggplot(aes(trat, comp)) +\n  geom_boxplot(outlier.color = NA,\n               fill = \"yellow\",\n               size = 0.5,\n               width = 0.2) +\n  geom_jitter(width = 0.15,\n              height = 0,\n              color = \"blue\") +\n  scale_y_continuous(limits = c(5,20),\n                     n.breaks = 10) +\n  labs(y = \"Lesion size (mm)\") + labs(x = \" \") +\n  theme_classic()\n\np_box\n\n\n\n\n#Gráfico de Barra\n\np_bars <- mg |>\n  group_by(trat) |>\n  summarise(comp_mean = mean(comp), \n            comp_sd = sd(comp)) |> \n  ggplot(aes(trat, comp_mean)) +\n  geom_col(width = 0.3,\n           color = \"black\",\n           fill = \"orange\") +\n  geom_point() +\n  scale_y_continuous(limits = c(0,20),\n                     n.breaks = 6) +\n  labs(y = \"Lesion size (mm)\") + labs(x = \" \") +\ngeom_errorbar(aes(ymin = comp_mean - comp_sd,       \n                  ymax = comp_mean + comp_sd,\n                  width = 0.05))\np_bars\n\n\n\n\nSe mudar o argumento color dentro de geom_col() muda as bordas da coluna e o fill muda o preenchimento interno.\n\n\nGráfico de distribuição de dados\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.3\n\np_means <- mg |>\n  group_by(trat) |>\n  summarise(comp_mean = mean(comp), \n            comp_sd = sd(comp)) |> \n  ggplot(aes(trat, comp_mean)) +\n  geom_point() +\n  scale_y_continuous(limits = c(6,20),\n                     n.breaks = 6) +\n  labs(y = \"Lesion size (mm)\") + labs(x = \" \") +\ngeom_errorbar(aes(ymin = comp_mean - comp_sd,       \n                  ymax = comp_mean + comp_sd,\n                  width = 0.05)) +\n  theme_economist()\n\nggsave(\"Gráfico DP.png\")\n\nSaving 7 x 5 in image\n\np_means\n\n\n\n\n#Prancha de gráficos Usando a biblioteca patchwork\n\nlibrary(patchwork)\n\nWarning: package 'patchwork' was built under R version 4.2.3\n\n(p_box | p_bars) +\n  plot_annotation(tag_levels = \"A\",\n                  title = \"Gráficos que impressionam\")\n\n\n\n\nAgora fazendo os graficos de barras invertidos\n\nsurvey <- read_excel(\"dados-diversos.xlsx\",\n                     sheet = \"survey\")\n\nsurvey |> \n  filter(state == \"RS\") |> \n  count(species, residue) |> \n  ggplot(aes(species, n)) +\n  geom_col(width = 0.8,\n           color = \"black\",\n           fill = \"yellow\") +\n  facet_wrap(~residue) +\n  #ele separa os isolados baseado em uma divisão (residue)\n  \n  coord_flip() +\n  #coord_flip inverte as coordenadas, então ele troca os eixos x e y de lugar.\nlabs(y = \" Number of isolates\", \n     x = \"  \",\n     title = \"O gráfico de milhões\") + \ntheme_classic()"
  },
  {
    "objectID": "what is r.html",
    "href": "what is r.html",
    "title": "O que é o R?",
    "section": "",
    "text": "R é uma linguagem de programação e um ambiente de desenvolvimento voltado principalmente para a análise estatística e a manipulação de dados. Ele foi criado por Ross Ihaka e Robert Gentleman na década de 1990 e é amplamente utilizado por estatísticos, cientistas de dados, pesquisadores e profissionais de áreas relacionadas.\nA linguagem R é conhecida por sua flexibilidade e poder em lidar com análise de dados, modelagem estatística, visualização e desenvolvimento de gráficos. Ela suporta uma ampla variedade de técnicas estatísticas e algoritmos avançados, tornando-se uma escolha popular para tarefas relacionadas a dados.\nPrincipais características do R:\n1. Vetorização: O R é uma linguagem vetorizada, o que significa que é otimizado para realizar operações em vetores e matrizes. Isso permite escrever código conciso e eficiente para manipulação de dados.\n2. Bibliotecas e pacotes: O R possui uma vasta coleção de pacotes, que são bibliotecas de código desenvolvidas por terceiros para estender a funcionalidade básica do R. Esses pacotes fornecem funções e métodos especializados para uma ampla gama de tarefas, desde análise estatística até visualização de dados.\n3. Gráficos e visualização: O R oferece recursos poderosos para criar visualizações gráficas de alta qualidade. Existem várias bibliotecas e pacotes disponíveis para criar uma ampla gama de gráficos, como gráficos de dispersão, histogramas, gráficos de barras, gráficos de linha, gráficos de pizza e muito mais.\n4. Análise estatística: O R é amplamente utilizado para análise estatística. Ele possui uma ampla gama de funções estatísticas integradas para realizar cálculos estatísticos básicos e avançados, como testes de hipóteses, regressão linear, análise de variância, modelagem preditiva e muito mais.\n5. Integração e interoperabilidade: O R pode ser integrado com outras linguagens de programação, como C, C++, Python e Java, permitindo estender suas funcionalidades e aproveitar bibliotecas externas.\n6. Comunidade e recursos: O R possui uma comunidade ativa de usuários e desenvolvedores que contribuem com pacotes, tutoriais, exemplos e suporte online. Há uma vasta quantidade de recursos disponíveis, como documentação oficial, fóruns de discussão, grupos de usuários e repositórios de código.\nEm suma, o R é uma linguagem de programação versátil e poderosa para análise estatística e manipulação de dados. Sua natureza vetorizada, suporte a pacotes e bibliotecas, recursos de visualização e foco na análise estatística o tornam uma escolha popular para profissionais e pesquisadores que trabalham com dados."
  }
]